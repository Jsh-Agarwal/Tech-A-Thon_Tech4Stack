{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from PIL import Image, ImageTk\n",
    "import tkinter as tk\n",
    "from concurrent.futures import ThreadPoolExecutor  # For parallel processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of image paths (update paths with actual image filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = ['obj1.jpg', 'obj2.jpg', 'obj3.jpg', 'obj4.jpg']  # Replace with your image filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_output_structure():\n",
    "    \"\"\"Create organized output directory structure\"\"\"\n",
    "    base_dir = \"output\"\n",
    "    subdirs = [\"preprocessed\", \"csv_files\", \"annotated\", \"text_reports\"]\n",
    "    \n",
    "    for subdir in subdirs:\n",
    "        path = os.path.join(base_dir, subdir)\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "    \n",
    "    return base_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_report(image_path, detection_results, processing_time, output_dir):\n",
    "    \"\"\"Generate detailed text report for each image\"\"\"\n",
    "    basename = os.path.basename(image_path)\n",
    "    report_path = os.path.join(output_dir, \"text_reports\", f\"{basename}_report.txt\")\n",
    "    \n",
    "    with open(report_path, 'w') as f:\n",
    "        f.write(f\"Analysis Report for {basename}\\n\")\n",
    "        f.write(\"=\"* 50 + \"\\n\\n\")\n",
    "        f.write(f\"Processing Time: {processing_time:.2f} seconds\\n\")\n",
    "        f.write(f\"Number of Boxes Detected: {len(detection_results)}\\n\\n\")\n",
    "        \n",
    "        f.write(\"Detailed Box Information:\\n\")\n",
    "        f.write(\"-\"* 30 + \"\\n\")\n",
    "        for idx, box in enumerate(detection_results, 1):\n",
    "            f.write(f\"\\nBox #{idx}:\\n\")\n",
    "            f.write(f\"  Center Position: ({box['x']:.2f}, {box['y']:.2f})\\n\")\n",
    "            f.write(f\"  Dimensions: {box['width']}x{box['height']} pixels\\n\")\n",
    "    cv2.drawContours(all_contours_img, filtered_cnt, -1, (0, 255, 0), 2)\n",
    "    plt.imshow(all_contours_img)\n",
    "    plt.title(f\"Detected Contours for {image_path}: {len(filtered_cnt)}\")\n",
    "    plt.show()\n",
    "\n",
    "    # Prepare data for logging\n",
    "    data = []\n",
    "    for c in filtered_cnt:\n",
    "        x, y, w, h = cv2.boundingRect(c)\n",
    "        aspect_ratio = float(w) / h\n",
    "        area = cv2.contourArea(c)\n",
    "        rect = cv2.minAreaRect(c)\n",
    "        box = cv2.boxPoints(rect)\n",
    "        box = np.int32(box)\n",
    "        angle = rect[2]\n",
    "        data.append({\n",
    "            \"X\": x,\n",
    "            \"Y\": y,\n",
    "            \"Width\": w,\n",
    "            \"Height\": h,\n",
    "            \"Area\": area,\n",
    "            \"Aspect Ratio\": aspect_ratio,\n",
    "            \"Orientation\": angle\n",
    "        })\n",
    "\n",
    "    # Log data to a CSV file\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(output_csv_name, index=False)\n",
    "    print(f\"Detection results saved to '{output_csv_name}'.\")\n",
    "\n",
    "    # Display final result\n",
    "    final_output = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    cv2.drawContours(final_output, filtered_cnt, -1, (0, 255, 0), 2)\n",
    "    plt.imshow(final_output)\n",
    "    plt.title(f\"Final Detected Boxes for {image_path}: {len(filtered_cnt)}\")\n",
    "    plt.show()\n",
    "    print(f\"Detected Boxes for {image_path}: {len(filtered_cnt)}\")\n",
    "    end_time = time.time()\n",
    "    processing_time = end_time - start_time\n",
    "    print(f\"Processing time for {image_path}: {processing_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_images(image_paths, target_size=(640, 640), output_dir=\"preprocessed_images\"):\n",
    "    \"\"\"Preprocess images by resizing and saving them to output_dir.\"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    preprocessed_images = []\n",
    "    \n",
    "    for idx, path in enumerate(image_paths):\n",
    "        image = Image.open(path)\n",
    "        cv_image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)\n",
    "        resized_image = cv2.resize(cv_image, target_size, interpolation=cv2.INTER_LINEAR)\n",
    "        preprocessed_images.append((resized_image, path))\n",
    "\n",
    "        # Save preprocessed image\n",
    "        output_path = os.path.join(output_dir, f\"preprocessed_image_{idx+1}.jpg\")\n",
    "        cv2.imwrite(output_path, resized_image)\n",
    "    return preprocessed_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_boxes(image):\n",
    "    \"\"\"Detect boxes in the image using OpenCV.\"\"\"\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    edges = cv2.Canny(blurred, 50, 150)\n",
    "    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    boxes = []\n",
    "    for contour in contours:\n",
    "        epsilon = 0.02 * cv2.arcLength(contour, True)\n",
    "        approx = cv2.approxPolyDP(contour, epsilon, True)\n",
    "        \n",
    "        if len(approx) == 4:  # Detecting quadrilateral (box)\n",
    "            x, y, w, h = cv2.boundingRect(approx)\n",
    "            center_x = x + w / 2\n",
    "            center_y = y + h / 2\n",
    "            angle = cv2.minAreaRect(contour)[-1]  # Get the angle of rotation\n",
    "            \n",
    "            boxes.append({\n",
    "                \"x\": round(center_x, 2),\n",
    "                \"y\": round(center_y, 2),\n",
    "                \"z\": 0,  # Placeholder for depth information\n",
    "                \"orientation\": round(angle, 2),  # Angle of the rotated bounding box\n",
    "                \"width\": w,\n",
    "                \"height\": h\n",
    "            })\n",
    "    return boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_box_detection(images):\n",
    "    \"\"\"Run box detection on a list of images in parallel.\"\"\"\n",
    "    detection_results = []\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        detection_results = list(executor.map(lambda image: detect_boxes(image[0]), images))\n",
    "    return detection_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_detections_to_csv(detection_results, images, output_dir=\"detection_csv\"):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    csv_paths = []\n",
    "    for idx, (detections, (_, image_path)) in enumerate(zip(detection_results, images)):\n",
    "        df = pd.DataFrame(detections)\n",
    "        csv_path = os.path.join(output_dir, f\"detections_{os.path.basename(image_path)}.csv\")\n",
    "        df.to_csv(csv_path, index=False)\n",
    "        csv_paths.append(csv_path)\n",
    "    return csv_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlay_detections_on_images(images, detection_results, output_dir=\"annotated_images\"):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    annotated_paths = []\n",
    "    for idx, ((image, image_path), detections) in enumerate(zip(images, detection_results)):\n",
    "        for detection in detections:\n",
    "            x, y = int(detection[\"x\"]), int(detection[\"y\"])\n",
    "            w, h = detection[\"width\"], detection[\"height\"]\n",
    "            angle = detection[\"orientation\"]\n",
    "            \n",
    "            # Draw the bounding box and the center\n",
    "            box_points = cv2.boxPoints(((x, y), (w, h), angle))\n",
    "            box_points = np.int32(box_points)\n",
    "            cv2.drawContours(image, [box_points], 0, (0, 255, 0), 2)\n",
    "            cv2.circle(image, (x, y), 5, (0, 255, 0), -1)\n",
    "            \n",
    "            # Add orientation label\n",
    "            cv2.putText(image, f\"Angle: {angle}Â°\", (x + 10, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
    "        \n",
    "        # Save annotated image\n",
    "        output_path = os.path.join(output_dir, f\"annotated_{os.path.basename(image_path)}\")\n",
    "        cv2.imwrite(output_path, image)\n",
    "        annotated_paths.append(output_path)\n",
    "    return annotated_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_images_tkinter(images):\n",
    "    root = tk.Tk()\n",
    "    root.title(\"Image Viewer\")\n",
    "    def show_image(index):\n",
    "        if 0 <= index < len(images):\n",
    "            image, path = images[index]\n",
    "            rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            pil_image = Image.fromarray(rgb_image)\n",
    "            imgtk = ImageTk.PhotoImage(image=pil_image)\n",
    "            panel.configure(image=imgtk)\n",
    "            panel.image = imgtk\n",
    "            label.configure(text=f\"Image {index + 1}/{len(images)}: {os.path.basename(path)}\")\n",
    "            root.current_index = index\n",
    "    def next_image():\n",
    "        show_image(root.current_index + 1)\n",
    "    def prev_image():\n",
    "        show_image(root.current_index - 1)\n",
    "    panel = tk.Label(root)\n",
    "    panel.pack()\n",
    "    label = tk.Label(root, text=\"\", font=(\"Arial\", 12))\n",
    "    label.pack()\n",
    "    btn_prev = tk.Button(root, text=\"Previous\", command=prev_image)\n",
    "    btn_prev.pack(side=\"left\")\n",
    "    btn_next = tk.Button(root, text=\"Next\", command=next_image)\n",
    "    btn_next.pack(side=\"right\")\n",
    "    root.current_index = 0\n",
    "    show_image(root.current_index)\n",
    "    root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image_path):\n",
    "    \"\"\"Process a single image and detect boxes\"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Read image\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"Error: Could not read image {image_path}\")\n",
    "        return\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply thresholding\n",
    "    _, binary = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Filter contours based on area and aspect ratio\n",
    "    filtered_cnt = []\n",
    "    for c in contours:\n",
    "        area = cv2.contourArea(c)\n",
    "        if area > 1000:  # Minimum area threshold\n",
    "            x, y, w, h = cv2.boundingRect(c)\n",
    "            aspect_ratio = float(w)/h\n",
    "            if 0.2 < aspect_ratio < 5:  # Aspect ratio threshold\n",
    "                filtered_cnt.append(c)\n",
    "    \n",
    "    # Display results\n",
    "    all_contours_img = image.copy()\n",
    "    output_csv_name = f\"{image_path}_boxes.csv\"\n",
    "\n",
    "    # ...rest of process_image function..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Create output directories\n",
    "    output_dir = create_output_structure()\n",
    "    \n",
    "    # Process each image both ways\n",
    "    for image_path in image_paths:\n",
    "        # Traditional single-image processing\n",
    "        process_image(image_path)\n",
    "        \n",
    "    # Parallel processing pipeline\n",
    "    preprocessed_images = preprocess_images(image_paths, output_dir=os.path.join(output_dir, \"preprocessed\"))\n",
    "    detection_results = run_box_detection(preprocessed_images)\n",
    "    csv_paths = save_detections_to_csv(detection_results, preprocessed_images, \n",
    "                                     output_dir=os.path.join(output_dir, \"csv_files\"))\n",
    "    annotated_paths = overlay_detections_on_images(preprocessed_images, detection_results, \n",
    "                                                 output_dir=os.path.join(output_dir, \"annotated\"))\n",
    "    \n",
    "    # Display results\n",
    "    display_images_tkinter(preprocessed_images)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
